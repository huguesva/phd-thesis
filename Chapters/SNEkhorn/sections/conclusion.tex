% !TeX root = ../paper.tex

\section{Conclusion}\label{sec:conclusion}

We have introduced a new principled and efficient method for constructing symmetric entropic affinities. Unlike the current formulation that enforces symmetry through an orthogonal projection, our approach allows control over the entropy in each point thus achieving entropic affinities' primary goal. Additionally, it produces a DS-normalized affinity and thus benefits from the well-known advantages of this normalization. Our affinity takes as input the same perplexity parameter as EAs and can thus be used with little hassle for practitioners. We demonstrate experimentally that both our affinity and DR algorithm (SNEkhorn), leveraging a doubly stochastic kernel in the latent space, achieve substantial improvements over state-of-the-art approaches.

% Although our work enhances clustering abilities which are often the prime focus when one runs \texttt{t-SNE}, 
Note that in the present work we do not address the issue of large-scale dependencies that are not faithfully represented in the low-dimensional space \cite{van2022probabilistic}. The latter shall be treated in future works. 
Among other promising research directions, one could focus on building multi-scale versions of symmetric entropic affinities \cite{lee2015multi} as well as fast approximations for SNEkhorn forces by adapting \eg Barnes-Hut \cite{van2013barnes} or interpolation-based methods \cite{linderman2019fast} to the doubly stochastic setting. It could also be interesting to use SEAs in order to study the training dynamics of transformers \cite{zhai2023sigmareparam}.

\section*{Acknowledgments} 
The authors are grateful to Mathurin Massias, Jean Feydy and Aurélien Garivier for insightful discussions.
This project was supported in part by the ANR projects AllegroAssai ANR-19-CHIA-0009, SingleStatOmics ANR-18-CE45-0023 and OTTOPIA ANR-20-CHIA-0030. This work was also supported by the ACADEMICS grant of the IDEXLYON, project of the Université de Lyon, PIA operated by ANR-16-IDEX-0005.
